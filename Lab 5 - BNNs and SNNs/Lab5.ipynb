{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Binary Neural Networks\n","\n","Existing deep neural networks use 32 bits, 16 bits or 8 bits to encode each weight and activation, making them large, slow and power-hungry. This prohibits many applications in resource-constrained environments.\n","\n","Binary Neural Network is a type of neural network that activations (or called features) and weights are 1-bit values in all the hidden layers (except the input and output layers). In a few words, BNN is an extremely compacted case of CNN - they have the same structures except for the different precision activations and weights. The use of BNNs enables not only significant reduction in memory usage, but also huge computational complexity improvements - the replacement of multiply-accumulation operations by `XNOR` and `bitcount` operations.\n","\n","Today, we'll use `Larq` - an open-source Python library for training neural networks with extremely low-precision weights and activations.\n","\n","You can find out more here: https://docs.larq.dev/larq/\n","\n","Larq is build on top of `TensorFlow` which is Python library for training neural networks, just like `PyTorch`. Because of that, we need to get familiar with this framework.\n","\n","First, install and import nessessery libraries."],"metadata":{"id":"wHGC0EFt3aZF"}},{"cell_type":"code","source":["!pip install larq larq-zoo larq-compute-engine"],"metadata":{"id":"3fkUb7mzgmGD"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1n_xcqlrsaMY"},"outputs":[],"source":["import tensorflow as tf\n","import larq as lq"]},{"cell_type":"markdown","source":["We'll stick with simple 3-conv-layers CNN and MNIST dataset. This time, we'll implement it with `TensorFlow`\n","\n","First, we use `tf.keras.datasets.mnist.load_data()` to download a dataset. Then, we need to reshape images to `(numer_of_samples, image_width, image_height, number_of_channels)`. Finally, we normalize image values to be between -1 and 1."],"metadata":{"id":"sZuhOF30TX-9"}},{"cell_type":"code","source":["(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n","\n","train_images = train_images.reshape((60000, ... , ... , ... )) #TODO: Put the widht, height and number of channels here\n","test_images = test_images.reshape((10000, ... , ... , ...)) #TODO: Put the widht, height and number of channels here\n","\n","# Normalize pixel values to be between -1 and 1\n","train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1"],"metadata":{"id":"7cnaAnDMsovx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, we need to create our model. We'll use the same architecture as in `PyTorch`:\n","\n","```\n","nn.Conv2d(input_channels,32,3,padding=(1,1))\n","nn.BatchNorm2d(32)\n","nn.ReLU()\n","nn.MaxPool2d(2,2)\n","\n","nn.Conv2d(32,64,3,padding=(1,1))\n","nn.BatchNorm2d(64)\n","nn.ReLU()\n","nn.MaxPool2d(2,2)\n","\n","nn.Conv2d(64,128,3)\n","nn.BatchNorm2d(128)\n","nn.ReLU()\n","\n","nn.Flatten(),\n","nn.Linear(CNN_out_size, num_of_cls),\n","nn.Softmax(dim=1)\n","```\n","\n","In `TensorFlow` however we define model with `tf.keras.models.Sequential()` and then we add layers one by one with `model.add()`.\n","\n","Create model with the help of documentation (https://keras.io/api/layers/) and following tips. You're going to need following layers:\n","\n","- In `PyTorch` we created convolutional layers with `Conv2d(in_ch, out_ch, kernel_size, padding=(x,x))`.  For `TrensorFlow` we use `tf.keras.layers.Conv2D(out_ch, kernel_size, strides=(x,x), padding=\"same\")`.\n","- For `stride=(x,x)` and `padding=\"same\"` we get the same result as with `padding=(x,x)` in PyTorch. We don't have to specify number of input channels, but we have to specify `input_shape=(w,h,ch)` parameter for the first `Conv2D` layer.\n","- The activation function is not added as a additional layer, but as `activation=\"relu\"` parameter to `Conv2D`\n","- You'll need `tf.keras.layers.BatchNormalization(scale=False)`, `tf.keras.layers.MaxPooling2D((2, 2))`, `tf.keras.layers.Dense(output_size)` and `tf.keras.layers.Flatten()` layers.\n","- The last layer (softmax) in our model should be `tf.keras.layers.Activation(\"softmax\")`"],"metadata":{"id":"h0qky25Y34Pn"}},{"cell_type":"code","source":["CNN = tf.keras.models.Sequential()\n","\n","CNN.add(tf.keras.layers.Conv2D(...)) # TODO: Enter parameters\n","CNN.add( ... )                       # TODO: Add another layer\n","\n","# TODO: Add all layers (the same ones as in PyTorch CNN model)"],"metadata":{"id":"Ztc3uPjk3wm7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Hopefully, we have our network ready to go! You can use `CNN.summary()` function to see our ready network with it's shapes and parameters."],"metadata":{"id":"MtG9rfTt--ng"}},{"cell_type":"code","source":["CNN.summary()"],"metadata":{"id":"tquhxcLk8kPe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let's train our network! After defining model layers and connections we need to compile it with `model.compile()` function. Google it and study its arguments. We should use `adam` optimizer, `[’accuracy’]`\n","metric and `tf.keras.losses.SparseCategoricalCrossentropy` loss.\n","\n","Then, we run training with `model.fit()` function. Google it and study its arguments. We'll train `CNN` with batch size of `64` for `5` epochs with `train_images` and `train_labels`. After training, evaluate network with `CNN.evaluate()`, where you pass only `test_images` and `test_labels`. Print the resulting accuracy. It should be around 99%!"],"metadata":{"id":"R9qhy7nQ_VhE"}},{"cell_type":"code","source":["CNN.compile( ... ) # TODO: Fill the gaps\n","\n","CNN.fit( ... ) # TODO: Fill the gaps\n","\n","test_loss, test_acc = CNN.evaluate( ... ) # TODO: Fill the gaps\n","\n"," # TODO: Print the accuracy."],"metadata":{"id":"1HlONKMo9Pbv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["We got familiar with `TensorFlow` basics and we can carry on with BNNs.\n","\n","Create new model with `tf.keras.models.Sequential()` and call it `BNN`. Use `model.add()` function to add all nessesery layers to this model. However, you'll need to replace all `Conv2D` and `Dense` layers with their binary counterparts. Use `lq.layers.QuantConv2D()` instead of `tf.keras.layers.Conv2D()` and `lq.layers.QuantDense()` instead of `tf.keras.layers.Dense()`.\n","\n","They use more or less the same parameters, but additionally, you have to update thair quantizers. In BNNs, the quantization function\n","$$\n","q(x) = \\begin{cases}\n","    -1 & x < 0 \\\\\\\n","    1 & x \\geq 0\n","\\end{cases}\n","$$\n","is used in the forward pass to binarize the activations and the latent full precision weights. The gradient of this function is zero almost everywhere which prevents the model from learning.\n","\n","To be able to train the model the gradient is instead estimated using the Straight-Through Estimator (STE):\n","$$\n","\\frac{\\partial q(x)}{\\partial x} = \\begin{cases}\n","    1 & \\left|x\\right| \\leq 1 \\\\\\\n","    0 & \\left|x\\right| > 1\n","\\end{cases}\n","$$\n","\n","In Larq this can be done by using `input_quantizer=\"ste_sign\"` and `kernel_quantizer=\"ste_sign\"`.\n","Additionally, the latent full precision weights are clipped to -1 and 1 using `kernel_constraint=\"weight_clip\"`.\n","\n","For the first Conv2d layer add parameters `kernel_quantizer=\"ste_sign\"` and `kernel_constraint=\"weight_clip\"`. For the next ones (both `QuantConv2D` and `QuantDense`) use those two and `input_quantizer=\"ste_sign\"`. This is why we don't quantize the inputs to the first convolutional layer (as is common for BNN training). All other layers should stay the same as in `CNN`."],"metadata":{"id":"lpnfcPAcAOxY"}},{"cell_type":"code","source":["BNN = tf.keras.models.Sequential()\n","\n","BNN.add(lq.layers.QuantConv2D(...)) # TODO: Enter parameters\n","BNN.add( ... )                      # TODO: Add another layer\n","\n","# TODO: Add all layers"],"metadata":{"id":"DDQd9U-hoPiT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["You can use `lq.models.summary(BNN)` function to see our ready network with it's shapes and parameters. Study the quantization summary at the bottom."],"metadata":{"id":"KtqxtCnbDWnt"}},{"cell_type":"code","source":["lq.models.summary(BNN)"],"metadata":{"id":"MFadMgRhkx6t"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, comple, fit for 5 epochs and evaluate your `BNN` (the same way as before). Print the result. Is such a network enough for such a task?"],"metadata":{"id":"tE6yPpFmDlXO"}},{"cell_type":"code","source":["BNN.compile( ... ) # TODO: Fill the gaps\n","\n","BNN.fit( ... ) # TODO: Fill the gaps\n","\n","test_loss, test_acc = BNN.evaluate( ... ) # TODO: Fill the gaps\n","\n"," # TODO: Print the accuracy."],"metadata":{"id":"VUrOsuemk3ja"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Extenction exercise**\n","\n","Deploy this network for ARM-based board (like RaspberryPI) or Android app with Larq Compute Engine. Benchmark it's performance.\n","\n","Find out more here: https://docs.larq.dev/compute-engine/"],"metadata":{"id":"F7stUeBGEBwQ"}},{"cell_type":"markdown","source":["# Spiking Neural Networks\n","\n","Spiking Neural Networks (SNNs) are a type of artificial neural network that is designed to simulate the behavior of neurons in the brain. In a traditional artificial neural network (ANN), the neurons are modeled as having a continuous activation value that changes over time, whereas in an SNN, the neurons are modeled as having discrete \"spikes\" of activation that occur at specific\n","points in time.\n","\n","SNNs are inspired by the way the neurons in the brain work. In the brain, neurons communicate with each other by sending electrical pulses, or spikes, along their axons. These spikes propagate to the dendrites of other neurons and, if the total input to a neuron exceeds a certain threshold, the neuron will generate a spike in response. SNNs use a similar concept: the neurons\n","in an SNN have a threshold, and if the total input to a neuron exceeds that threshold, the neuron will generate a spike.\n","\n","SNNs have several advantages over traditional ANNs. One of the main advantages is that SNNs are more energy efficient, because they only communicate when they need to, instead of continuously sending signals. Additionally, SNNs can be more robust to noise and other disturbances, because they can use the timing of spikes to communicate information. Currently SNNs are not as popular as traditional neural networks (ANNs) in industry and research, because of their higher complexity, specialized hardware requirements and less mature toolkits.\n","\n","SNN takes a set of spikes as input and produces a set of spikes as output. The general idea is:\n","- Each neuron has a value that is equivalent to the electrical potential of biological neurons at any given time.\n","- The value of a neuron can change according to its mathematical model; for example, if a neuron gets a spike from an upstream neuron, its value may rise or fall.\n","- If a neuron’s value surpasses a certain threshold, the neuron will send a single impulse to each downstream neuron connected to the first one, and the neuron’s value will immediately drop below its average.\n","- As a result, the neuron will go through a refractory period similar to that of a biological neuron. The neuron’s value will gradually return to its average over time.\n","\n","We'll use `SnnTorch` framework. We'll not dive deep into this idea, we'll just get familiar with the basics. SNNs are very tricky to train, and their research field is still quite new. Moreover, they need state-of-the-art neuromorphic computing platforms like Brainchip's Akida or Intel's Loihi.\n","\n","Read more here: https://snntorch.readthedocs.io/en/latest/index.html\n","\n","First, install and import libraries:"],"metadata":{"id":"AGgn0Ay8Ec3N"}},{"cell_type":"code","source":["!pip install tonic --quiet\n","!pip install snntorch --quiet\n","import tonic\n","import matplotlib.pyplot as plt\n","import snntorch.spikeplot as splt\n","from IPython.display import HTML\n","import snntorch as snn\n","from snntorch import surrogate\n","from snntorch import functional as SF\n","from snntorch import spikeplot as splt\n","from snntorch import utils\n","import torch.nn as nn\n","import torch\n","from torch.utils.data import DataLoader"],"metadata":{"id":"_pCCVe9SUUUe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Let's start our journey with the input spikes. Neuromorphic NNs work best with... neuromorphic sensors like Event Cameras.\n","\n","An event camera (also known as Dynamic Vision Sensor – DVS) is a neuromorphic sensor that takes its inspiration from the human eye. Unlike classical cameras, which record the brightness (colour) level for a given pixel every specified time interval (frame per second parameter), a DVS records brightness changes independently (asynchronously) for individual pixels. Consequently, the data captured by the camera does not depend on the clock but the dynamics of the scene. As a result, a stream of events is available on the output, where each is described by 4 values:\n","* x & y co-ordinates correspond to an address in a $34 \\times 34$ grid.\n","\n","* The timestamp of the event is recorded in microseconds.\n","\n","* The polarity refers to whether an on-spike (+1) or an off-spike (-1) occured; i.e., an increase in brightness or a decrease in brightness.\n","\n","We can use an output of DVS as input to SNN (with some basics transformation, but it does not metter for now). In this task we'll use NMNIST dataset, with is just MNIST dataset recorded with event camera.\n","\n","Use the following code to download a NMNIST dataset and visualise it. What we can see is the events captured for each pixel (x, y) in time. The colour means a postive or negative polarity."],"metadata":{"id":"bB9P8z9iuWZo"}},{"cell_type":"code","source":["nmnist = tonic.datasets.NMNIST(save_to='./data', train=False)\n","\n","events, label = nmnist[0]\n","transform = tonic.transforms.ToFrame(\n","    sensor_size=nmnist.sensor_size,\n","    time_window=10000,\n",")\n","frames = transform(events)\n","animation = tonic.utils.plot_animation(frames)\n","\n","# Display the animation inline in a Jupyter notebook\n","from IPython.display import HTML\n","HTML(animation.to_jshtml())"],"metadata":{"id":"xhjyeQyNUhMf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["During this task, we'll not train the network. We'll use already pretrained model (from UPEL). Use following line to upload `snn.pth` file, and then run cells with the SNN definition and loading of the weights."],"metadata":{"id":"dw_IBE0wxa8a"}},{"cell_type":"code","source":["from google.colab import files\n","files.upload()\n"],"metadata":{"id":"6GIs145EmRXt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","\n","# neuron and simulation parameters\n","spike_grad = surrogate.atan()\n","beta = 0.5\n","\n","#  Initialize Network\n","net = nn.Sequential(nn.Conv2d(2, 12, 5),\n","                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n","                    nn.MaxPool2d(2),\n","                    nn.Conv2d(12, 32, 5),\n","                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n","                    nn.MaxPool2d(2),\n","                    nn.Flatten(),\n","                    nn.Linear(32*5*5, 10),\n","                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n","                    )\n","\n","testset = tonic.datasets.NMNIST(save_to='./tmp/data', transform=transform, train=False)\n","testloader = DataLoader(testset, batch_size=1, collate_fn=tonic.collation.PadTensors(batch_first=False))\n","net.load_state_dict(torch.load(\"snn.pth\"))"],"metadata":{"id":"LCOVwO9Nig0-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now, let's study the output of the SNN. As we already now, the output is spiking as well. We remeber, that for CNNs the output for MNIST classification is a 10-values vector, where each value refers to the probability, that the object belongs to each class.\n","\n","For SNNs we have a 10-values vector as well, but each can only be active or inactive (0 or 1). So how can we tell, to which class does the object belongs? We just count the number of spikes registered for each class!\n","\n","In the following code, we take a sample from dataset, we perform the forward-pass and visualize the output. Study it!"],"metadata":{"id":"1D04sddKyB1c"}},{"cell_type":"code","source":["def forward_pass(net, data):\n","  spk_rec = []\n","  utils.reset(net)  # resets hidden states for all LIF neurons in net\n","\n","  for step in range(data.size(0)):  # data.size(0) = number of time steps\n","      spk_out, mem_out = net(data[step])\n","      spk_rec.append(spk_out)\n","\n","  return torch.stack(spk_rec)\n","\n","event_tensor, target = next(iter(testloader))\n","spk_rec = forward_pass(net, event_tensor)\n","idx = 0\n","fig, ax = plt.subplots(facecolor='w', figsize=(12, 7))\n","labels=['0', '1', '2', '3', '4', '5', '6', '7', '8','9']\n","print(f\"The target label is: {target}\")\n","anim = splt.spike_count(spk_rec[:, idx].detach().cpu(), fig, ax, labels=labels,\n","                        animate=True, interpolate=5)\n","HTML(anim.to_html5_video())"],"metadata":{"id":"MHzSnPmIm7ew"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["That's it! There were not much for you to do in this part of the class. The teacher will ask you few questions about SNNs just to verify, that you got the general idea :)"],"metadata":{"id":"yhfoLSVIzGMV"}}]}