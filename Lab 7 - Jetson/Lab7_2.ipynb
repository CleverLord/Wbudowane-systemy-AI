{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wHGC0EFt3aZF"
   },
   "source": [
    "# CNN inference with eGPU - part 2\n",
    "\n",
    "Today we'll run neural networks inference on NVIDIA Jetson Nano eGPUs.\n",
    "\n",
    "You can find out more here: https://www.nvidia.com/pl-pl/autonomous-machines/embedded-systems/jetson-nano-developer-kit/\n",
    "\n",
    "First, install and import nessessery libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3fkUb7mzgmGD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow-datasets in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (4.8.3)\n",
      "Requirement already satisfied: absl-py in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (1.4.0)\n",
      "Requirement already satisfied: click in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (8.1.7)\n",
      "Requirement already satisfied: dm-tree in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (0.1.8)\n",
      "Requirement already satisfied: etils>=0.9.0 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (1.5.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (1.24.4)\n",
      "Requirement already satisfied: promise in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (2.3)\n",
      "Requirement already satisfied: protobuf>=3.12.2 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (3.19.6)\n",
      "Requirement already satisfied: psutil in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (5.9.6)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (2.31.0)\n",
      "Requirement already satisfied: tensorflow-metadata in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (1.13.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (2.3.0)\n",
      "Requirement already satisfied: toml in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (0.10.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (4.66.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-datasets) (1.15.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (2023.10.0)\n",
      "Requirement already satisfied: importlib_resources in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (6.1.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (4.8.0)\n",
      "Requirement already satisfied: zipp in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets) (3.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.3.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from requests>=2.19.0->tensorflow-datasets) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from click->tensorflow-datasets) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from promise->tensorflow-datasets) (1.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in c:\\users\\krzys\\documents\\github\\wbudowane-systemy-ai\\.venv\\lib\\site-packages (from tensorflow-metadata->tensorflow-datasets) (1.61.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-datasets\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ErsrtA8dfLU"
   },
   "source": [
    "Before we start, chech if the GPU is available. In this part of the laboratory we don't need GPU - if you use Colab - change runtime type! It you use local PC - google how to disable GPU for TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "D7lAmE8MdbFa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZuhOF30TX-9"
   },
   "source": [
    "Today, we are going to try a bit bigger model and harder dataset. We'll try running Imagenet classification with ResNet network.\n",
    "\n",
    "More about the dataset: https://www.image-net.org/\n",
    "\n",
    "More about the network: https://keras.io/api/applications/resnet/\n",
    "\n",
    "It would take some time to train this model, so we'll just use ready, pretrained neural network. Use `tf.keras.applications.ResNet50()` function to create `CNN` instance (just study the link above). Use `include_top=True`, `weights=\"imagenet\"` and `classes=1000`. Based on documentation answer the question - what is model's input size and what is it's output size?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "_VYYPAsaTp0V"
   },
   "outputs": [],
   "source": [
    "# Today, we are going to try a bit bigger model and harder dataset. We'll try running Imagenet classification with ResNet network.\n",
    "# More about the dataset: https://www.image-net.org/\n",
    "# More about the network: https://keras.io/api/applications/resnet/\n",
    "# It would take some time to train this model, so we'll just use ready, pretrained neural network. Use `tf.keras.applications.ResNet50()` function to create `CNN` instance (just study the link above). Use `include_top=True`, `weights=\"imagenet\"` and `classes=1000`. Based on documentation answer the question - what is model's input size and what is it's output size?\n",
    "model = tf.keras.applications.ResNet50(include_top=True, weights=\"imagenet\", classes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqckVEc6Xkog"
   },
   "source": [
    "Now, let's download the dataset with `tfds` module. Use `tfds.load()` function with `imagenet_v2` dataset name (this is the dataset used for MobileNet training), `split='test[70%:]` (we need just 3000 samples), and `shuffle_files=True` and `as_supervised=True` parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7cnaAnDMsovx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\krzys\\tensorflow_datasets\\imagenet_v2\\matched-frequency\\3.0.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a973cd8ee94e4f599058e5e43b806421",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4b55c1fefb419aa945e3fc2cca6ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dd174b63fcb44c9aaef91676f08190c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "DownloadError",
     "evalue": "Failed to get url https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-matched-frequency.tar.gz. HTTP code: 403.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDownloadError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\Lab 7 - Jetson\\Lab7_2.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krzys/Documents/GitHub/Wbudowane-systemy-AI/Lab%207%20-%20Jetson/Lab7_2.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Now, let's download the dataset with `tfds` module. Use `tfds.load()` function with `imagenet_v2` dataset name (this is the dataset used for MobileNet training), `split='test[70%:]` (we need just 3000 samples), and `shuffle_files=True` and `as_supervised=True` parameters.\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/krzys/Documents/GitHub/Wbudowane-systemy-AI/Lab%207%20-%20Jetson/Lab7_2.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow_datasets\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtfds\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/krzys/Documents/GitHub/Wbudowane-systemy-AI/Lab%207%20-%20Jetson/Lab7_2.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m ds \u001b[39m=\u001b[39m tfds\u001b[39m.\u001b[39;49mload (\u001b[39m'\u001b[39;49m\u001b[39mimagenet_v2\u001b[39;49m\u001b[39m'\u001b[39;49m, split\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtest[70\u001b[39;49m\u001b[39m%\u001b[39;49m\u001b[39m:]\u001b[39;49m\u001b[39m'\u001b[39;49m, shuffle_files\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, as_supervised\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\load.py:617\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\u001b[0m\n\u001b[0;32m    615\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[0;32m    616\u001b[0m   download_and_prepare_kwargs \u001b[39m=\u001b[39m download_and_prepare_kwargs \u001b[39mor\u001b[39;00m {}\n\u001b[1;32m--> 617\u001b[0m   dbuilder\u001b[39m.\u001b[39mdownload_and_prepare(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdownload_and_prepare_kwargs)\n\u001b[0;32m    619\u001b[0m \u001b[39mif\u001b[39;00m as_dataset_kwargs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    620\u001b[0m   as_dataset_kwargs \u001b[39m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\logging\\__init__.py:169\u001b[0m, in \u001b[0;36m_FunctionDecorator.__call__\u001b[1;34m(self, function, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    167\u001b[0m metadata \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_call()\n\u001b[0;32m    168\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 169\u001b[0m   \u001b[39mreturn\u001b[39;00m function(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    170\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[0;32m    171\u001b[0m   metadata\u001b[39m.\u001b[39mmark_error()\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:640\u001b[0m, in \u001b[0;36mDatasetBuilder.download_and_prepare\u001b[1;34m(self, download_dir, download_config, file_format)\u001b[0m\n\u001b[0;32m    638\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mread_from_directory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_dir)\n\u001b[0;32m    639\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 640\u001b[0m   \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(\n\u001b[0;32m    641\u001b[0m       dl_manager\u001b[39m=\u001b[39;49mdl_manager,\n\u001b[0;32m    642\u001b[0m       download_config\u001b[39m=\u001b[39;49mdownload_config,\n\u001b[0;32m    643\u001b[0m   )\n\u001b[0;32m    645\u001b[0m   \u001b[39m# NOTE: If modifying the lines below to put additional information in\u001b[39;00m\n\u001b[0;32m    646\u001b[0m   \u001b[39m# DatasetInfo, you'll likely also want to update\u001b[39;00m\n\u001b[0;32m    647\u001b[0m   \u001b[39m# DatasetInfo.read_from_directory to possibly restore these attributes\u001b[39;00m\n\u001b[0;32m    648\u001b[0m   \u001b[39m# when reading from package data.\u001b[39;00m\n\u001b[0;32m    649\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minfo\u001b[39m.\u001b[39mdownload_size \u001b[39m=\u001b[39m dl_manager\u001b[39m.\u001b[39mdownloaded_size\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:1448\u001b[0m, in \u001b[0;36mGeneratorBasedBuilder._download_and_prepare\u001b[1;34m(self, dl_manager, download_config)\u001b[0m\n\u001b[0;32m   1446\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1447\u001b[0m   optional_pipeline_kwargs \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1448\u001b[0m split_generators \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_split_generators(  \u001b[39m# pylint: disable=unexpected-keyword-arg\u001b[39;00m\n\u001b[0;32m   1449\u001b[0m     dl_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptional_pipeline_kwargs\n\u001b[0;32m   1450\u001b[0m )\n\u001b[0;32m   1451\u001b[0m \u001b[39m# TODO(tfds): Could be removed once all datasets are migrated.\u001b[39;00m\n\u001b[0;32m   1452\u001b[0m \u001b[39m# https://github.com/tensorflow/datasets/issues/2537\u001b[39;00m\n\u001b[0;32m   1453\u001b[0m \u001b[39m# Legacy mode (eventually convert list[SplitGeneratorLegacy] -> dict)\u001b[39;00m\n\u001b[0;32m   1454\u001b[0m split_generators \u001b[39m=\u001b[39m split_builder\u001b[39m.\u001b[39mnormalize_legacy_split_generators(\n\u001b[0;32m   1455\u001b[0m     split_generators\u001b[39m=\u001b[39msplit_generators,\n\u001b[0;32m   1456\u001b[0m     generator_fn\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_examples,\n\u001b[0;32m   1457\u001b[0m     is_beam\u001b[39m=\u001b[39m\u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, BeamBasedBuilder),\n\u001b[0;32m   1458\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\datasets\\imagenet_v2\\imagenet_v2_dataset_builder.py:104\u001b[0m, in \u001b[0;36mBuilder._split_generators\u001b[1;34m(self, dl_manager)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Returns a SplitGenerator for the test set.\"\"\"\u001b[39;00m\n\u001b[0;32m    102\u001b[0m variant_url \u001b[39m=\u001b[39m _IMAGENET_V2_URLS[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder_config\u001b[39m.\u001b[39mvariant]\n\u001b[0;32m    103\u001b[0m imagenet_v2_root \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m--> 104\u001b[0m     dl_manager\u001b[39m.\u001b[39;49mdownload_and_extract(variant_url),\n\u001b[0;32m    105\u001b[0m     _TAR_TOPDIR[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilder_config\u001b[39m.\u001b[39mvariant],\n\u001b[0;32m    106\u001b[0m )\n\u001b[0;32m    107\u001b[0m \u001b[39mreturn\u001b[39;00m [\n\u001b[0;32m    108\u001b[0m     tfds\u001b[39m.\u001b[39mcore\u001b[39m.\u001b[39mSplitGenerator(\n\u001b[0;32m    109\u001b[0m         \u001b[39m# The dataset provides only a test split.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m     ),\n\u001b[0;32m    114\u001b[0m ]\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:686\u001b[0m, in \u001b[0;36mDownloadManager.download_and_extract\u001b[1;34m(self, url_or_urls)\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_downloader\u001b[39m.\u001b[39mtqdm():\n\u001b[0;32m    685\u001b[0m   \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_extractor\u001b[39m.\u001b[39mtqdm():\n\u001b[1;32m--> 686\u001b[0m     \u001b[39mreturn\u001b[39;00m _map_promise(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_extract, url_or_urls)\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:829\u001b[0m, in \u001b[0;36m_map_promise\u001b[1;34m(map_fn, all_inputs)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    826\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    827\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    828\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[1;32m--> 829\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[0;32m    830\u001b[0m     \u001b[39mlambda\u001b[39;49;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[0;32m    831\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tree\\__init__.py:435\u001b[0m, in \u001b[0;36mmap_structure\u001b[1;34m(func, *structures, **kwargs)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[1;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tree\\__init__.py:435\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39mfor\u001b[39;00m other \u001b[39min\u001b[39;00m structures[\u001b[39m1\u001b[39m:]:\n\u001b[0;32m    433\u001b[0m   assert_same_structure(structures[\u001b[39m0\u001b[39m], other, check_types\u001b[39m=\u001b[39mcheck_types)\n\u001b[0;32m    434\u001b[0m \u001b[39mreturn\u001b[39;00m unflatten_as(structures[\u001b[39m0\u001b[39m],\n\u001b[1;32m--> 435\u001b[0m                     [func(\u001b[39m*\u001b[39;49margs) \u001b[39mfor\u001b[39;00m args \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m\u001b[39mmap\u001b[39m(flatten, structures))])\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:830\u001b[0m, in \u001b[0;36m_map_promise.<locals>.<lambda>\u001b[1;34m(p)\u001b[0m\n\u001b[0;32m    825\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Map the function into each element and resolve the promise.\"\"\"\u001b[39;00m\n\u001b[0;32m    826\u001b[0m all_promises \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[0;32m    827\u001b[0m     map_fn, all_inputs\n\u001b[0;32m    828\u001b[0m )  \u001b[39m# Apply the function\u001b[39;00m\n\u001b[0;32m    829\u001b[0m res \u001b[39m=\u001b[39m tree_utils\u001b[39m.\u001b[39mmap_structure(\n\u001b[1;32m--> 830\u001b[0m     \u001b[39mlambda\u001b[39;00m p: p\u001b[39m.\u001b[39;49mget(), all_promises\n\u001b[0;32m    831\u001b[0m )  \u001b[39m# Wait promises\u001b[39;00m\n\u001b[0;32m    832\u001b[0m \u001b[39mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\promise\\promise.py:512\u001b[0m, in \u001b[0;36mPromise.get\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    510\u001b[0m target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_target()\n\u001b[0;32m    511\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_wait(timeout \u001b[39mor\u001b[39;00m DEFAULT_TIMEOUT)\n\u001b[1;32m--> 512\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target_settled_value(_raise\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\promise\\promise.py:516\u001b[0m, in \u001b[0;36mPromise._target_settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_target_settled_value\u001b[39m(\u001b[39mself\u001b[39m, _raise\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m    515\u001b[0m     \u001b[39m# type: (bool) -> Any\u001b[39;00m\n\u001b[1;32m--> 516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_target()\u001b[39m.\u001b[39;49m_settled_value(_raise)\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\promise\\promise.py:226\u001b[0m, in \u001b[0;36mPromise._settled_value\u001b[1;34m(self, _raise)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[39mif\u001b[39;00m _raise:\n\u001b[0;32m    225\u001b[0m     raise_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n\u001b[1;32m--> 226\u001b[0m     reraise(\u001b[39mtype\u001b[39;49m(raise_val), raise_val, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_traceback)\n\u001b[0;32m    227\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fulfillment_handler0\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\six.py:719\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    717\u001b[0m     \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[0;32m    718\u001b[0m         \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m--> 719\u001b[0m     \u001b[39mraise\u001b[39;00m value\n\u001b[0;32m    720\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    721\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\promise\\promise.py:844\u001b[0m, in \u001b[0;36m_process_future_result.<locals>.handle_future_result\u001b[1;34m(future)\u001b[0m\n\u001b[0;32m    841\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mhandle_future_result\u001b[39m(future):\n\u001b[0;32m    842\u001b[0m     \u001b[39m# type: (Any) -> None\u001b[39;00m\n\u001b[0;32m    843\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 844\u001b[0m         resolve(future\u001b[39m.\u001b[39;49mresult())\n\u001b[0;32m    845\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    846\u001b[0m         tb \u001b[39m=\u001b[39m exc_info()[\u001b[39m2\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:439\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    437\u001b[0m     \u001b[39mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    438\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39m==\u001b[39m FINISHED:\n\u001b[1;32m--> 439\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__get_result()\n\u001b[0;32m    441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_condition\u001b[39m.\u001b[39mwait(timeout)\n\u001b[0;32m    443\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state \u001b[39min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\_base.py:391\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception:\n\u001b[0;32m    390\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 391\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_exception\n\u001b[0;32m    392\u001b[0m     \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    393\u001b[0m         \u001b[39m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    394\u001b[0m         \u001b[39mself\u001b[39m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\concurrent\\futures\\thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[0;32m     59\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n\u001b[0;32m     60\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfuture\u001b[39m.\u001b[39mset_exception(exc)\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:229\u001b[0m, in \u001b[0;36m_Downloader._sync_download\u001b[1;34m(self, url, destination_path, verify)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39mexcept\u001b[39;00m tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mUnimplementedError:\n\u001b[0;32m    227\u001b[0m   \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[39mwith\u001b[39;00m _open_url(url, verify\u001b[39m=\u001b[39mverify) \u001b[39mas\u001b[39;00m (response, iter_content):\n\u001b[0;32m    230\u001b[0m   fname \u001b[39m=\u001b[39m _get_filename(response)\n\u001b[0;32m    231\u001b[0m   path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(destination_path, fname)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py:119\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[39mdel\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwds, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunc\n\u001b[0;32m    118\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 119\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mnext\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgen)\n\u001b[0;32m    120\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgenerator didn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt yield\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:302\u001b[0m, in \u001b[0;36m_open_with_requests\u001b[1;34m(url, **kwargs)\u001b[0m\n\u001b[0;32m    300\u001b[0m   url \u001b[39m=\u001b[39m _normalize_drive_url(url)\n\u001b[0;32m    301\u001b[0m \u001b[39mwith\u001b[39;00m session\u001b[39m.\u001b[39mget(url, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m response:\n\u001b[1;32m--> 302\u001b[0m   _assert_status(response)\n\u001b[0;32m    303\u001b[0m   \u001b[39myield\u001b[39;00m (response, response\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39mio\u001b[39m.\u001b[39mDEFAULT_BUFFER_SIZE))\n",
      "File \u001b[1;32mc:\\Users\\krzys\\Documents\\GitHub\\Wbudowane-systemy-AI\\.venv\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:329\u001b[0m, in \u001b[0;36m_assert_status\u001b[1;34m(response)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Ensure the URL response is 200.\"\"\"\u001b[39;00m\n\u001b[0;32m    328\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[1;32m--> 329\u001b[0m   \u001b[39mraise\u001b[39;00m DownloadError(\n\u001b[0;32m    330\u001b[0m       \u001b[39m'\u001b[39m\u001b[39mFailed to get url \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. HTTP code: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    331\u001b[0m           response\u001b[39m.\u001b[39murl, response\u001b[39m.\u001b[39mstatus_code\n\u001b[0;32m    332\u001b[0m       )\n\u001b[0;32m    333\u001b[0m   )\n",
      "\u001b[1;31mDownloadError\u001b[0m: Failed to get url https://s3-us-west-2.amazonaws.com/imagenetv2public/imagenetv2-matched-frequency.tar.gz. HTTP code: 403."
     ]
    }
   ],
   "source": [
    "# Now, let's download the dataset with `tfds` module. Use `tfds.load()` function with `imagenet_v2` dataset name (this is the dataset used for MobileNet training), `split='test[70%:]` (we need just 3000 samples), and `shuffle_files=True` and `as_supervised=True` parameters.\n",
    "import tensorflow_datasets as tfds\n",
    "ds = tfds.load ('imagenet_v2', split='test[70%:]', shuffle_files=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YO7dEYvVYNfl"
   },
   "source": [
    "Perfect. Now, we have both pretrained model and test dataset ready. We can benchmark the model. Implement benchmarking similarly as in previous lab, but:\n",
    "- calulate not only throughput, and TOP1 accuracy, but also TOP5 accuracy (is correct label found in 5 classes with highest prediction probability?). The `((-preds[0]).argsort()[:5])` function may prove useful here.\n",
    "- you can loop through dataset with `for image, label in tfds.as_numpy(ds):`\n",
    "- each image should be resized to model input size and then reshaped to `(1,input_size, input_size, nr_of_channels)` before `predict` function. Just before model's input use `preprocess_input()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XP-tGiaTsVD3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "input_size = 224\n",
    "nr_of_channels = 3\n",
    "\n",
    "N_warmup_run = 50\n",
    "N_run = 500\n",
    "\n",
    "# Initialize variables to keep track of results\n",
    "start_time = time.time()\n",
    "correct_top1 = 0\n",
    "correct_top5 = 0\n",
    "\n",
    "# Use tqdm to add a progress bar\n",
    "for image, label in tqdm(tfds.as_numpy(ds), total=N_run + N_warmup_run):\n",
    "    img = cv2.resize(image, (input_size, input_size))\n",
    "    img = preprocess_input(img)\n",
    "    img = np.reshape(img, (1, input_size, input_size, nr_of_channels))\n",
    "    preds = model.predict(img,verbose=0)\n",
    "    preds_decoded = decode_predictions(preds, top=5)[0]\n",
    "    top1_label = preds_decoded[0][1]\n",
    "    top5_labels = [label for (_, label, _) in preds_decoded]\n",
    "\n",
    "    # Warm-up run\n",
    "    if N_warmup_run > 0:\n",
    "        N_warmup_run -= 1\n",
    "    else:\n",
    "        if label == top1_label:\n",
    "            correct_top1 += 1\n",
    "        if label in top5_labels:\n",
    "            correct_top5 += 1\n",
    "        N_run -= 1\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate throughput\n",
    "elapsed_time = end_time - start_time\n",
    "throughput = N_run / elapsed_time\n",
    "\n",
    "# Calculate TOP1 and TOP5 accuracy\n",
    "top1_accuracy = correct_top1 / N_run\n",
    "top5_accuracy = correct_top5 / N_run\n",
    "\n",
    "print(\"Throughput: {:.2f} samples per second\".format(throughput))\n",
    "print(\"TOP1 Accuracy: {:.2f}\".format(top1_accuracy))\n",
    "print(\"TOP5 Accuracy: {:.2f}\".format(top5_accuracy))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ocBxRmZ3X2bX"
   },
   "source": [
    "We got familiar with ResNet50 model and ImageNet dataset.\n",
    "Now we can carry on with Jetson Nano. Show this part of exercise to the teacher and ask for Jeston Nano board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l64lI9Ddd6Y-"
   },
   "source": [
    "**Prepare Jetson Nano**\n",
    "- First, take Jetson Nano board, connect it to power source, internet, monitor, mouse and keyboard.\n",
    "- Log in to Jetson and finish OS instalation (the boards were not used yet).\n",
    "- Open terminal and add cuda to PATH `export PATH=$PATH:/usr/local/cuda-10/bin`. Verify CUDA with `nvcc --version`.\n",
    "- Connect USB camera to Jetson board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "afI3eBHDd8wJ"
   },
   "source": [
    "Well, we have our Jetson Nano ready to go! We could load our Resnet50 model with Keras, convert and build it with TensorRT and run inference (remember, that `converter.build()` should always be run on final device, so the model would be optimazed for particular hardware).\n",
    "\n",
    "However, this eGPU board however has only 2GB RAM (shared between CPU and GPU). This would take some time (it's possible, especially with more advanced Jetson boards).\n",
    "\n",
    "Today, to save some time, we'll use NVIDIA Jetson Inference tools for testing! We'll compare how does this little eGPU with limited memory does in comparison with our CPU-based benchmark.\n",
    "\n",
    "**Run camera DEMO**\n",
    "- clone https://github.com/dusty-nv/jetson-inference repository on Jetson\n",
    "- run Jetson-inference docker with `./docker/run.sh`\n",
    "- inside the docker, we should be able to test inference for supported models (ResNet50 is supported) - change directory to `./build/aarch64/bin/`\n",
    "- run `./imagenet-camera.py --help` and study the arguments. We want to perform the inference for ResNet50 model, with TOP5 prediction displayed for our USB camera (it's source should be visible with `ls /dev/video*`)\n",
    "- run `./imagenet-camera.py` with correct parameters. Study the outputs. What is the model precision in converted TensorRT model? Why? What is FPS for this demo?\n",
    "- try to direct camera at some objects that can be correctly classified with ImageNet-pretrained network\n",
    "\n",
    "**Extention exercise**\n",
    "\n",
    "Compare JetsonNano performance with your GPU (or Colab's GPU). Enable GPU in Colab (or locally), use TensorRT to convert CNN to FP16, build the engine and benchmark the model. What is the difference in TOP1 and TOP5 accuracy after TensorRT optimization? What is the throughput for local GPU?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
