{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CNN inference with eGPU - part 2\n",
        "\n",
        "Today we'll run neural networks inference on NVIDIA Jetson Nano eGPUs.\n",
        "\n",
        "You can find out more here: https://www.nvidia.com/pl-pl/autonomous-machines/embedded-systems/jetson-nano-developer-kit/\n",
        "\n",
        "First, install and import nessessery libraries."
      ],
      "metadata": {
        "id": "wHGC0EFt3aZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --upgrade tensorrt\n",
        "!pip install tensorflow-datasets\n",
        "import tensorflow as tf\n",
        "import tensorrt"
      ],
      "metadata": {
        "id": "3fkUb7mzgmGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we start, chech if the GPU is available (we going to need it!)."
      ],
      "metadata": {
        "id": "7ErsrtA8dfLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.config.list_physical_devices('GPU'))"
      ],
      "metadata": {
        "id": "D7lAmE8MdbFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today, we are going to try a bit bigger model and harder dataset. We'll try running Imagenet classification with MobileNet network.\n",
        "\n",
        "More about the dataset: https://www.image-net.org/\n",
        "\n",
        "More about the network: https://keras.io/api/applications/mobilenet/\n",
        "\n",
        "It would take some time to train this model, so we'll just use ready, pretrained neural network. Use `tf.keras.applications.MobileNet()` function to create `CNN` instance (just study the link above). Use `include_top=True`, `weights=\"imagenet\"` and `classes=1000`. Based on documentation answer the question - what is model's input size and what is it's output size?\n",
        "\n"
      ],
      "metadata": {
        "id": "sZuhOF30TX-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CNN = tf.keras.applications.MobileNet( ... )"
      ],
      "metadata": {
        "id": "_VYYPAsaTp0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's download the dataset with `tfds` module. Use `tfds.load()` function with `imagenet_v2` dataset name (this is the dataset used for MobileNet training), `split='test[70%:]` (we need just 3000 samples), and `shuffle_files=True` and `as_supervised=True` parameters."
      ],
      "metadata": {
        "id": "RqckVEc6Xkog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "ds = tfds.load( ... )"
      ],
      "metadata": {
        "id": "7cnaAnDMsovx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perfect. Now, we have both pretrained model and test dataset ready. We can benchmark the model. Implement benchmarking similarly as in previous lab, but:\n",
        "- calulate not only throughput, and TOP1 accuracy, but also TOP5 accuracy (is correct label found in 5 classes with highest prediction probability?). The `((-preds[0]).argsort()[:5])` function may prove useful here.\n",
        "- you can loop through dataset with `for image, label in tfds.as_numpy(ds):`\n",
        "- each image should be resized to model input size and then reshaped to `(1,input_size, input_size, nr_of_channels)` before `predict` function. Just before model's input use `preprocess_input()`"
      ],
      "metadata": {
        "id": "YO7dEYvVYNfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
        "\n",
        "# Benchmarking throughput and TOP1/TOP5 accuracy\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "N_warmup_run = 50\n",
        "N_run = 500\n",
        "\n",
        "for image, label in tfds.as_numpy(ds):\n",
        "  # TO DO\n",
        "\n",
        "\n",
        "print( ... ) # Throughput\n",
        "print( ... ) # TOP1 accuracy\n",
        "print( ... ) # TOP1 accuracy"
      ],
      "metadata": {
        "id": "XP-tGiaTsVD3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After benchmarking - save model with `CNN.save()`. We got familiar with MobileNet and ImageNet. Now we can carry on with Jetson Nano. Show this part of exercise to the teacher and ask for Jeston Nano board."
      ],
      "metadata": {
        "id": "ocBxRmZ3X2bX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAVED_MODEL_DIR=\"saved_model\"\n",
        "CNN.save(SAVED_MODEL_DIR)"
      ],
      "metadata": {
        "id": "Zm-88TKxXGay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our task is to run inference on Jetson Nano with TensorRT model. You are going to:\n",
        "1. Prepare the Jetson Nano board.\n",
        "2. Convert Mobilenet with TensorRT.\n",
        "3. Run inference on example image.\n",
        "4. **Extended** Benchmark Jetson Nano inference.\n",
        "5. **Extension exercise** Connect camera and run live classification."
      ],
      "metadata": {
        "id": "rskpRVbTapDb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare the Jetson Nano board\n",
        "- First, take Jetson Nano board, connect it to power source, internet, monitor, mouse and keyboard.\n",
        "- Log in to Jetson and finish OS instalation (the boards were not used yet).\n",
        "- Open terminal and add cuda to PATH `export PATH=$PATH:/usr/local/cuda-10/bin`. Verify CUDA with `nvcc --version`.\n",
        "- Download NVIDIA Tensorflow docker `sudo docker pull nvcr.io/nvidia/l4t-tensorflow:r32.7.1-tf2.7-py3`\n",
        "- Run NVIDIA Tensorflow docker with `sudo docker run -it --rm --runtime nvidia --network host -v /home/nano/Documents:/home/ nvcr.io/nvidia/l4t-tensorflow:r32.7.1-tf2.7-py3`. Now, you can use TensorRT, TensorFlow and CUDA in this terminal window. Moreover, the path `/home/nano/Documents/` outside of docker is linked to `/home/` inside of docker.\n",
        "\n",
        "2. Convert MobileNet with TensorRT\n",
        "\n",
        "Use the code from Lab6 to convert `MobileNet` model to TensorRT. Start with FP32 model (to make it simple). You can move `save_model` created here to Jetson or create CNN on Jetson (`tf.keras.applications.MobileNet()`)\n",
        "\n",
        "3. Run inference on example image.\n",
        "- Warmup model with dummy imput (`np.random`)\n",
        "- Pass image to `infer` and analize network output.\n",
        "- You can get example images from imagenet from `https://github.com/EliSchwartz/imagenet-sample-images.git` repository. Use PIL to read and resize images.\n",
        "\n",
        "4. **Extension exercise** - Loop thorugh all images, benchmark TensorRT model.\n",
        "\n",
        "5. **Extension exercise** - Implement simple application that uses USB camera and TensorRT for live classification."
      ],
      "metadata": {
        "id": "W8opMWVOcReD"
      }
    }
  ]
}